{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 16.0,
  "eval_steps": 100,
  "global_step": 900,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.17777777777777778,
      "grad_norm": 1.1456103324890137,
      "learning_rate": 8.92857142857143e-06,
      "loss": 1.6241,
      "step": 10
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 1.0913846492767334,
      "learning_rate": 1.785714285714286e-05,
      "loss": 1.5584,
      "step": 20
    },
    {
      "epoch": 0.5333333333333333,
      "grad_norm": 0.914071798324585,
      "learning_rate": 2.6785714285714288e-05,
      "loss": 1.4519,
      "step": 30
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.7808189988136292,
      "learning_rate": 3.571428571428572e-05,
      "loss": 1.3215,
      "step": 40
    },
    {
      "epoch": 0.8888888888888888,
      "grad_norm": 1.0093995332717896,
      "learning_rate": 4.464285714285715e-05,
      "loss": 1.2228,
      "step": 50
    },
    {
      "epoch": 1.0666666666666667,
      "grad_norm": 0.8985193371772766,
      "learning_rate": 5.3571428571428575e-05,
      "loss": 1.2371,
      "step": 60
    },
    {
      "epoch": 1.2444444444444445,
      "grad_norm": 1.1291964054107666,
      "learning_rate": 6.25e-05,
      "loss": 1.0791,
      "step": 70
    },
    {
      "epoch": 1.4222222222222223,
      "grad_norm": 0.9593020677566528,
      "learning_rate": 7.142857142857143e-05,
      "loss": 1.0289,
      "step": 80
    },
    {
      "epoch": 1.6,
      "grad_norm": 1.1215709447860718,
      "learning_rate": 8.035714285714287e-05,
      "loss": 1.0398,
      "step": 90
    },
    {
      "epoch": 1.7777777777777777,
      "grad_norm": 1.3353396654129028,
      "learning_rate": 8.92857142857143e-05,
      "loss": 0.9908,
      "step": 100
    },
    {
      "epoch": 1.7777777777777777,
      "eval_loss": 0.9802068471908569,
      "eval_runtime": 3.5925,
      "eval_samples_per_second": 13.918,
      "eval_steps_per_second": 6.959,
      "step": 100
    },
    {
      "epoch": 1.9555555555555557,
      "grad_norm": 1.1533478498458862,
      "learning_rate": 9.821428571428572e-05,
      "loss": 1.0228,
      "step": 110
    },
    {
      "epoch": 2.1333333333333333,
      "grad_norm": 0.987558901309967,
      "learning_rate": 9.998445910004082e-05,
      "loss": 1.0178,
      "step": 120
    },
    {
      "epoch": 2.311111111111111,
      "grad_norm": 1.2676514387130737,
      "learning_rate": 9.992134075089084e-05,
      "loss": 0.8785,
      "step": 130
    },
    {
      "epoch": 2.488888888888889,
      "grad_norm": 1.2336872816085815,
      "learning_rate": 9.980973490458728e-05,
      "loss": 0.8813,
      "step": 140
    },
    {
      "epoch": 2.6666666666666665,
      "grad_norm": 1.2968043088912964,
      "learning_rate": 9.964974996142698e-05,
      "loss": 0.8598,
      "step": 150
    },
    {
      "epoch": 2.8444444444444446,
      "grad_norm": 1.6565775871276855,
      "learning_rate": 9.944154131125642e-05,
      "loss": 0.9081,
      "step": 160
    },
    {
      "epoch": 3.022222222222222,
      "grad_norm": 1.589822769165039,
      "learning_rate": 9.918531118254507e-05,
      "loss": 0.9548,
      "step": 170
    },
    {
      "epoch": 3.2,
      "grad_norm": 1.40223228931427,
      "learning_rate": 9.888130844596524e-05,
      "loss": 0.7258,
      "step": 180
    },
    {
      "epoch": 3.3777777777777778,
      "grad_norm": 1.791788935661316,
      "learning_rate": 9.852982837266955e-05,
      "loss": 0.7268,
      "step": 190
    },
    {
      "epoch": 3.5555555555555554,
      "grad_norm": 1.5631234645843506,
      "learning_rate": 9.81312123475006e-05,
      "loss": 0.6931,
      "step": 200
    },
    {
      "epoch": 3.5555555555555554,
      "eval_loss": 0.9486038684844971,
      "eval_runtime": 3.599,
      "eval_samples_per_second": 13.893,
      "eval_steps_per_second": 6.946,
      "step": 200
    },
    {
      "epoch": 3.7333333333333334,
      "grad_norm": 1.9954345226287842,
      "learning_rate": 9.768584753741134e-05,
      "loss": 0.6851,
      "step": 210
    },
    {
      "epoch": 3.911111111111111,
      "grad_norm": 2.0085432529449463,
      "learning_rate": 9.719416651541839e-05,
      "loss": 0.6837,
      "step": 220
    },
    {
      "epoch": 4.088888888888889,
      "grad_norm": 1.4569488763809204,
      "learning_rate": 9.665664684045333e-05,
      "loss": 0.6928,
      "step": 230
    },
    {
      "epoch": 4.266666666666667,
      "grad_norm": 2.224841356277466,
      "learning_rate": 9.607381059352038e-05,
      "loss": 0.5184,
      "step": 240
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 1.7127119302749634,
      "learning_rate": 9.544622387061055e-05,
      "loss": 0.5284,
      "step": 250
    },
    {
      "epoch": 4.622222222222222,
      "grad_norm": 2.2224273681640625,
      "learning_rate": 9.477449623286505e-05,
      "loss": 0.544,
      "step": 260
    },
    {
      "epoch": 4.8,
      "grad_norm": 2.2552688121795654,
      "learning_rate": 9.405928011452211e-05,
      "loss": 0.5329,
      "step": 270
    },
    {
      "epoch": 4.977777777777778,
      "grad_norm": 2.2471256256103516,
      "learning_rate": 9.330127018922194e-05,
      "loss": 0.527,
      "step": 280
    },
    {
      "epoch": 5.155555555555556,
      "grad_norm": 1.7131680250167847,
      "learning_rate": 9.250120269528546e-05,
      "loss": 0.4208,
      "step": 290
    },
    {
      "epoch": 5.333333333333333,
      "grad_norm": 2.444755792617798,
      "learning_rate": 9.165985472062246e-05,
      "loss": 0.4112,
      "step": 300
    },
    {
      "epoch": 5.333333333333333,
      "eval_loss": 1.1045516729354858,
      "eval_runtime": 3.5989,
      "eval_samples_per_second": 13.893,
      "eval_steps_per_second": 6.947,
      "step": 300
    },
    {
      "epoch": 5.511111111111111,
      "grad_norm": 2.365471124649048,
      "learning_rate": 9.077804344796302e-05,
      "loss": 0.4161,
      "step": 310
    },
    {
      "epoch": 5.688888888888889,
      "grad_norm": 2.229360580444336,
      "learning_rate": 8.985662536114613e-05,
      "loss": 0.4068,
      "step": 320
    },
    {
      "epoch": 5.866666666666667,
      "grad_norm": 2.3069796562194824,
      "learning_rate": 8.889649541323574e-05,
      "loss": 0.4194,
      "step": 330
    },
    {
      "epoch": 6.044444444444444,
      "grad_norm": 1.5629088878631592,
      "learning_rate": 8.789858615727265e-05,
      "loss": 0.3853,
      "step": 340
    },
    {
      "epoch": 6.222222222222222,
      "grad_norm": 2.4371635913848877,
      "learning_rate": 8.68638668405062e-05,
      "loss": 0.2703,
      "step": 350
    },
    {
      "epoch": 6.4,
      "grad_norm": 2.0597705841064453,
      "learning_rate": 8.579334246298593e-05,
      "loss": 0.3181,
      "step": 360
    },
    {
      "epoch": 6.5777777777777775,
      "grad_norm": 2.284719944000244,
      "learning_rate": 8.468805280142709e-05,
      "loss": 0.292,
      "step": 370
    },
    {
      "epoch": 6.7555555555555555,
      "grad_norm": 2.338344097137451,
      "learning_rate": 8.354907139929851e-05,
      "loss": 0.2769,
      "step": 380
    },
    {
      "epoch": 6.933333333333334,
      "grad_norm": 2.728445053100586,
      "learning_rate": 8.237750452411353e-05,
      "loss": 0.3012,
      "step": 390
    },
    {
      "epoch": 7.111111111111111,
      "grad_norm": 1.9670052528381348,
      "learning_rate": 8.117449009293668e-05,
      "loss": 0.2807,
      "step": 400
    },
    {
      "epoch": 7.111111111111111,
      "eval_loss": 1.2400095462799072,
      "eval_runtime": 3.598,
      "eval_samples_per_second": 13.897,
      "eval_steps_per_second": 6.948,
      "step": 400
    },
    {
      "epoch": 7.288888888888889,
      "grad_norm": 2.7691075801849365,
      "learning_rate": 7.994119656715002e-05,
      "loss": 0.2048,
      "step": 410
    },
    {
      "epoch": 7.466666666666667,
      "grad_norm": 2.1339821815490723,
      "learning_rate": 7.86788218175523e-05,
      "loss": 0.2127,
      "step": 420
    },
    {
      "epoch": 7.644444444444445,
      "grad_norm": 3.0073461532592773,
      "learning_rate": 7.738859196089358e-05,
      "loss": 0.2306,
      "step": 430
    },
    {
      "epoch": 7.822222222222222,
      "grad_norm": 1.7685649394989014,
      "learning_rate": 7.60717601689749e-05,
      "loss": 0.2131,
      "step": 440
    },
    {
      "epoch": 8.0,
      "grad_norm": 5.443517208099365,
      "learning_rate": 7.472960545147038e-05,
      "loss": 0.2535,
      "step": 450
    },
    {
      "epoch": 8.177777777777777,
      "grad_norm": 2.3453121185302734,
      "learning_rate": 7.33634314136531e-05,
      "loss": 0.1583,
      "step": 460
    },
    {
      "epoch": 8.355555555555556,
      "grad_norm": 2.108194589614868,
      "learning_rate": 7.197456499023225e-05,
      "loss": 0.1638,
      "step": 470
    },
    {
      "epoch": 8.533333333333333,
      "grad_norm": 2.029937267303467,
      "learning_rate": 7.056435515653059e-05,
      "loss": 0.1406,
      "step": 480
    },
    {
      "epoch": 8.71111111111111,
      "grad_norm": 2.2132580280303955,
      "learning_rate": 6.91341716182545e-05,
      "loss": 0.1631,
      "step": 490
    },
    {
      "epoch": 8.88888888888889,
      "grad_norm": 2.4523563385009766,
      "learning_rate": 6.768540348112907e-05,
      "loss": 0.1641,
      "step": 500
    },
    {
      "epoch": 8.88888888888889,
      "eval_loss": 1.3306117057800293,
      "eval_runtime": 3.5988,
      "eval_samples_per_second": 13.893,
      "eval_steps_per_second": 6.947,
      "step": 500
    },
    {
      "epoch": 9.066666666666666,
      "grad_norm": 1.793515682220459,
      "learning_rate": 6.621945790169036e-05,
      "loss": 0.1645,
      "step": 510
    },
    {
      "epoch": 9.244444444444444,
      "grad_norm": 1.5999675989151,
      "learning_rate": 6.473775872054521e-05,
      "loss": 0.107,
      "step": 520
    },
    {
      "epoch": 9.422222222222222,
      "grad_norm": 2.0029866695404053,
      "learning_rate": 6.324174507942637e-05,
      "loss": 0.1149,
      "step": 530
    },
    {
      "epoch": 9.6,
      "grad_norm": 3.8015363216400146,
      "learning_rate": 6.173287002338577e-05,
      "loss": 0.1084,
      "step": 540
    },
    {
      "epoch": 9.777777777777779,
      "grad_norm": 1.7377768754959106,
      "learning_rate": 6.021259908948402e-05,
      "loss": 0.1387,
      "step": 550
    },
    {
      "epoch": 9.955555555555556,
      "grad_norm": 2.197751045227051,
      "learning_rate": 5.868240888334653e-05,
      "loss": 0.1198,
      "step": 560
    },
    {
      "epoch": 10.133333333333333,
      "grad_norm": 1.5599991083145142,
      "learning_rate": 5.714378564496901e-05,
      "loss": 0.1043,
      "step": 570
    },
    {
      "epoch": 10.311111111111112,
      "grad_norm": 1.4933608770370483,
      "learning_rate": 5.559822380516539e-05,
      "loss": 0.0917,
      "step": 580
    },
    {
      "epoch": 10.488888888888889,
      "grad_norm": 2.139331102371216,
      "learning_rate": 5.404722453406017e-05,
      "loss": 0.083,
      "step": 590
    },
    {
      "epoch": 10.666666666666666,
      "grad_norm": 1.247467279434204,
      "learning_rate": 5.249229428303486e-05,
      "loss": 0.0853,
      "step": 600
    },
    {
      "epoch": 10.666666666666666,
      "eval_loss": 1.4982119798660278,
      "eval_runtime": 3.6045,
      "eval_samples_per_second": 13.872,
      "eval_steps_per_second": 6.936,
      "step": 600
    },
    {
      "epoch": 10.844444444444445,
      "grad_norm": 1.5261486768722534,
      "learning_rate": 5.0934943321545115e-05,
      "loss": 0.0833,
      "step": 610
    },
    {
      "epoch": 11.022222222222222,
      "grad_norm": 1.2553526163101196,
      "learning_rate": 4.9376684270229254e-05,
      "loss": 0.0984,
      "step": 620
    },
    {
      "epoch": 11.2,
      "grad_norm": 1.701124906539917,
      "learning_rate": 4.781903063173321e-05,
      "loss": 0.0629,
      "step": 630
    },
    {
      "epoch": 11.377777777777778,
      "grad_norm": 1.0221877098083496,
      "learning_rate": 4.626349532067879e-05,
      "loss": 0.0574,
      "step": 640
    },
    {
      "epoch": 11.555555555555555,
      "grad_norm": 1.4718865156173706,
      "learning_rate": 4.471158919420312e-05,
      "loss": 0.0615,
      "step": 650
    },
    {
      "epoch": 11.733333333333333,
      "grad_norm": 1.6380928754806519,
      "learning_rate": 4.316481958449634e-05,
      "loss": 0.0598,
      "step": 660
    },
    {
      "epoch": 11.911111111111111,
      "grad_norm": 1.3246357440948486,
      "learning_rate": 4.162468883476319e-05,
      "loss": 0.07,
      "step": 670
    },
    {
      "epoch": 12.088888888888889,
      "grad_norm": 0.6885108947753906,
      "learning_rate": 4.0092692840030134e-05,
      "loss": 0.0621,
      "step": 680
    },
    {
      "epoch": 12.266666666666667,
      "grad_norm": 2.686049461364746,
      "learning_rate": 3.857031959421553e-05,
      "loss": 0.0441,
      "step": 690
    },
    {
      "epoch": 12.444444444444445,
      "grad_norm": 1.2175554037094116,
      "learning_rate": 3.705904774487396e-05,
      "loss": 0.0441,
      "step": 700
    },
    {
      "epoch": 12.444444444444445,
      "eval_loss": 1.6082754135131836,
      "eval_runtime": 3.6011,
      "eval_samples_per_second": 13.885,
      "eval_steps_per_second": 6.942,
      "step": 700
    },
    {
      "epoch": 12.622222222222222,
      "grad_norm": 0.4998260736465454,
      "learning_rate": 3.556034515701852e-05,
      "loss": 0.0391,
      "step": 710
    },
    {
      "epoch": 12.8,
      "grad_norm": 1.2709753513336182,
      "learning_rate": 3.4075667487415785e-05,
      "loss": 0.0451,
      "step": 720
    },
    {
      "epoch": 12.977777777777778,
      "grad_norm": 1.2780518531799316,
      "learning_rate": 3.2606456770738636e-05,
      "loss": 0.0483,
      "step": 730
    },
    {
      "epoch": 13.155555555555555,
      "grad_norm": 0.6342048645019531,
      "learning_rate": 3.115414001894974e-05,
      "loss": 0.0401,
      "step": 740
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 0.526355504989624,
      "learning_rate": 2.9720127835276256e-05,
      "loss": 0.029,
      "step": 750
    },
    {
      "epoch": 13.511111111111111,
      "grad_norm": 0.8523580431938171,
      "learning_rate": 2.8305813044122097e-05,
      "loss": 0.0287,
      "step": 760
    },
    {
      "epoch": 13.688888888888888,
      "grad_norm": 0.7335214018821716,
      "learning_rate": 2.6912569338248315e-05,
      "loss": 0.0298,
      "step": 770
    },
    {
      "epoch": 13.866666666666667,
      "grad_norm": 0.9167590141296387,
      "learning_rate": 2.5541749944535554e-05,
      "loss": 0.0336,
      "step": 780
    },
    {
      "epoch": 14.044444444444444,
      "grad_norm": 0.4653192162513733,
      "learning_rate": 2.4194686309624663e-05,
      "loss": 0.0336,
      "step": 790
    },
    {
      "epoch": 14.222222222222221,
      "grad_norm": 0.8508287072181702,
      "learning_rate": 2.2872686806712035e-05,
      "loss": 0.0245,
      "step": 800
    },
    {
      "epoch": 14.222222222222221,
      "eval_loss": 1.693821668624878,
      "eval_runtime": 3.6002,
      "eval_samples_per_second": 13.888,
      "eval_steps_per_second": 6.944,
      "step": 800
    },
    {
      "epoch": 14.4,
      "grad_norm": 0.4209062159061432,
      "learning_rate": 2.157703546475539e-05,
      "loss": 0.0247,
      "step": 810
    },
    {
      "epoch": 14.577777777777778,
      "grad_norm": 0.41170912981033325,
      "learning_rate": 2.0308990721324927e-05,
      "loss": 0.0233,
      "step": 820
    },
    {
      "epoch": 14.755555555555556,
      "grad_norm": 0.5409049987792969,
      "learning_rate": 1.906978420031059e-05,
      "loss": 0.0235,
      "step": 830
    },
    {
      "epoch": 14.933333333333334,
      "grad_norm": 0.38718390464782715,
      "learning_rate": 1.7860619515673033e-05,
      "loss": 0.0255,
      "step": 840
    },
    {
      "epoch": 15.11111111111111,
      "grad_norm": 0.2655009329319,
      "learning_rate": 1.6682671102399805e-05,
      "loss": 0.0221,
      "step": 850
    },
    {
      "epoch": 15.28888888888889,
      "grad_norm": 0.2704254984855652,
      "learning_rate": 1.553708307580265e-05,
      "loss": 0.0209,
      "step": 860
    },
    {
      "epoch": 15.466666666666667,
      "grad_norm": 0.26605159044265747,
      "learning_rate": 1.4424968120263504e-05,
      "loss": 0.0213,
      "step": 870
    },
    {
      "epoch": 15.644444444444444,
      "grad_norm": 0.32803627848625183,
      "learning_rate": 1.3347406408508695e-05,
      "loss": 0.0186,
      "step": 880
    },
    {
      "epoch": 15.822222222222223,
      "grad_norm": 0.29835405945777893,
      "learning_rate": 1.230544455246101e-05,
      "loss": 0.0178,
      "step": 890
    },
    {
      "epoch": 16.0,
      "grad_norm": 0.618025004863739,
      "learning_rate": 1.130009458668863e-05,
      "loss": 0.022,
      "step": 900
    },
    {
      "epoch": 16.0,
      "eval_loss": 1.7607600688934326,
      "eval_runtime": 3.5916,
      "eval_samples_per_second": 13.921,
      "eval_steps_per_second": 6.961,
      "step": 900
    }
  ],
  "logging_steps": 10,
  "max_steps": 1120,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.6151862695061094e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
