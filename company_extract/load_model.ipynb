{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69cd28cf-bdbe-49f4-8c5a-08d8945fc238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/IPython/core/magics/osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'LLaMA-Factory'\n",
      "/workspace/LLaMA-Factory\n"
     ]
    }
   ],
   "source": [
    "%cd LLaMA-Factory\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb37948f-f04f-44fb-9c3a-b18e74d74ea1",
   "metadata": {},
   "source": [
    "## 학습전 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eedfe0e-ef1e-46da-adb7-2c07a58c95c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('meta-llama/Llama-3.2-3B-Instruct')\n",
    "model = AutoModelForCausalLM.from_pretrained('meta-llama/Llama-3.2-3B-Instruct')\n",
    "model = torch.nn.DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79d35a05-58db-4ca9-b5f9-97dd3dcc7bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##학습후 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea416ef8-fc4a-4edb-bc23-ef5e0a5d86b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc44c85d398147e2a34c4cf5321d04d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('./output_dir')\n",
    "model = AutoModelForCausalLM.from_pretrained('./output_dir')\n",
    "model = torch.nn.DataParallel(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "886695e9-d559-44c0-bdba-46c183e3eaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"당신은 회사명을 찾는 챗봇입니다. \\n\\n ## 지시 사항 ## \\n1. 주어진 입력에 나와있는 회사명을 찾으세요 \\n2. 회사명을 찾을수 없다면, 빈 파이썬 리스트를 출력하고, 임의로 답변하려고 시도하지 마세요. \\n3. 출력은 반드시 파이썬의 리스트 형태로 생성하십시오.\\n4. 뉴스데이터:이 주어지면 회사리스트: 다음에 파이썬 리스트 형태로 작성하세요.\"},\n",
    "    {\"role\": \"user\", \"content\": \"뉴스데이터: 인공지능(AI) 반도체 시장의 흐름이 ‘맞춤형’ 시대로 접어들면서 메모리 시장에도 지각변동이 일어날 것으로 전망된다. 수년간 AI 메모리 업계를 지배했던 고대역폭메모리(HBM) 외에도 다양한 D램이 차세대 AI 칩으로 거론되기 시작하면서 SK하이닉스의 시장 독주에도 균열이 생길 수 있다.2일 업계에 따르면 엔비디아가 독주하던 AI 반도체 시장에서 새로운 변화가 일어난 것은 ‘추론’ 시장이 고개를 들고 있기 때문이다. AI 반도체는 크게 학습용과 추론용으로 나뉜다. 학습용 반도체는 거대언어모델(LLM) 개발을 위해 방대한 데이터를 단순한 모델로 만들 때 활용된다.\"}\n",
    "]\n",
    "\n",
    "encodeds = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\")\n",
    "model_inputs = encodeds.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50a7db6b-1109-44d4-9d7f-ddd66e57b496",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = tokenizer.decode(model_inputs[0])+ '회사리스트 :'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "430d6557-9cee-488e-a101-e9ea403d073a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 02 Jan 2025\n",
      "\n",
      "당신은 회사명을 찾는 챗봇입니다. \n",
      "\n",
      " ## 지시 사항 ## \n",
      "1. 주어진 입력에 나와있는 회사명을 찾으세요 \n",
      "2. 회사명을 찾을수 없다면, 빈 파이썬 리스트를 출력하고, 임의로 답변하려고 시도하지 마세요. \n",
      "3. 출력은 반드시 파이썬의 리스트 형태로 생성하십시오.\n",
      "4. 뉴스데이터:이 주어지면 회사리스트: 다음에 파이썬 리스트 형태로 작성하세요.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "뉴스데이터: 인공지능(AI) 반도체 시장의 흐름이 ‘맞춤형’ 시대로 접어들면서 메모리 시장에도 지각변동이 일어날 것으로 전망된다. 수년간 AI 메모리 업계를 지배했던 고대역폭메모리(HBM) 외에도 다양한 D램이 차세대 AI 칩으로 거론되기 시작하면서 SK하이닉스의 시장 독주에도 균열이 생길 수 있다.2일 업계에 따르면 엔비디아가 독주하던 AI 반도체 시장에서 새로운 변화가 일어난 것은 ‘추론’ 시장이 고개를 들고 있기 때문이다. AI 반도체는 크게 학습용과 추론용으로 나뉜다. 학습용 반도체는 거대언어모델(LLM) 개발을 위해 방대한 데이터를 단순한 모델로 만들 때 활용된다.<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "회사리스트 : ['SK하이닉스', '엔비디아']<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "eos_token_id = tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model.module.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=512, eos_token_id=eos_token_id)\n",
    "    print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69068017-ab18-42de-9ea7-aa8492fd581d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094c0166c69742348b425f14d2f002b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7950bc5e399544e1a312cc23f0aa132c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6a76b821094424aad2adde14e7e5e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/1.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09b45c135e44c07942b2c2ed4104357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/irene93/Llama-3-Company-Extract/commit/b6b6327b940117d49fbe289c8d6fd1dc8a6d6ed0', commit_message='Upload folder using huggingface_hub', commit_description='', oid='b6b6327b940117d49fbe289c8d6fd1dc8a6d6ed0', pr_url=None, repo_url=RepoUrl('https://huggingface.co/irene93/Llama-3-Company-Extract', endpoint='https://huggingface.co', repo_type='model', repo_id='irene93/Llama-3-Company-Extract'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "username = \"irene93\"\n",
    "\n",
    "MODEL_NAME = 'Llama-3-Company-Extract'\n",
    "api.create_repo(\n",
    "    token=### 토큰값 ,\n",
    "    repo_id=f\"{username}/{MODEL_NAME}\",\n",
    "    repo_type=\"model\"\n",
    ")\n",
    "\n",
    "api.upload_folder(\n",
    "    token=### 토큰값 ,\n",
    "    repo_id=f\"{username}/{MODEL_NAME}\",\n",
    "    folder_path=\"output_dir\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e26c02-73bf-4732-a61f-87e04386a87e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
